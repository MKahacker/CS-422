{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  \n",
    " $$a. Gini = 1 - \\sum_{i=0}^n p_i^2  = 1 - \\frac{10^2} {20^2} + \\frac{10^2} {20^2} = 1 - \\frac{100 + 100} {400} = \\frac {1} {2}$$\n",
    " $$b. Gini = 1 - \\sum_{i=0}^n p_i^2  = 1 - \\frac{1^2} {20^2} + \\frac{1^2} {20^2}+ ... +\\frac{1^2} {20^2} = 1 - \\frac {1} {20} = \\frac{19} {20}$$\n",
    " $$c. Gini = 1 - \\sum_{i=0}^n p_i^2  = 1 - \\frac{1^2} {20^2} + \\frac{1^2} {20^2}+ ... +\\frac{1^2} {20^2} = 1 - \\frac {1} {20} = \\frac{19} {20}$$\n",
    "3. 7\n",
    "5. b\n",
    "6. t\n",
    "7. r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49382716049382713\n",
      "0.49382716049382713\n"
     ]
    }
   ],
   "source": [
    "exercise_3 = {\"a1\": [1,1,1,0,0,0,0,1,0], \"a2\": [1,1,0,0,1,1,0,0,1],\n",
    "              \"a3\":[1.0,6.0,5.0,4.0,7.0,3.0,8.0,7.0,5.0], \"Target\":[\"+\",\"+\",\"-\",\"+\",\"-\",\"-\",\"-\",\"+\",\"-\"]}\n",
    "pd_exr_3 = pd.DataFrame(data=exercise_3)\n",
    "pd_exr_3.describe()\n",
    "pd_pos_class = pd_exr_3[pd_exr_3[\"Target\"] == \"+\"]\n",
    "pd_neg_class = pd_exr_3[pd_exr_3[\"Target\"] == \"-\"]\n",
    "count_poss = np.square(pd_pos_class[\"Target\"].count()/pd_exr_3[\"Target\"].count())\n",
    "count_negs = np.square(pd_neg_class[\"Target\"].count()/pd_exr_3[\"Target\"].count())\n",
    "gini = 1 - (count_poss + count_negs)\n",
    "print(gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cust ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.91608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Cust ID\n",
       "count  20.00000\n",
       "mean   10.50000\n",
       "std     5.91608\n",
       "min     1.00000\n",
       "25%     5.75000\n",
       "50%    10.50000\n",
       "75%    15.25000\n",
       "max    20.00000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exercise_3 = {\"Cust ID\": [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "              \"Gender\": [\"M\",\"M\",\"M\",\"M\",\"M\",\"M\",\"F\",\"F\",\"F\",\"F\",\"M\",\"M\",\"M\",\"M\",\"F\",\"F\",\"F\",\"F\",\"F\",\"F\"], \n",
    "              \"Car Type\": [\"Family\",\"Sports\",\"Sports\",\"Sports\",\"Sports\",\"Sports\",\"Sports\",\"Sports\",\"Sports\",\"Luxury\",\"Family\",\"Family\",\"Family\",\"Luxury\",\"Luxury\",\"Luxury\",\"Luxury\",\"Luxury\",\"Luxury\",\"Luxury\"],\n",
    "              \"Shirt Size\":[\"Small\",\"Medium\",\"Medium\",\"Large\",\"Extra Large\",\"Extra Large\",\"Small\",\"Small\",\"Medium\",\"Large\",\"Large\",\"Extra Large\",\"Medium\",\"Extra Large\",\"Small\",\"Small\",\"Medium\",\"Medium\",\"Medium\",\"Large\"],\n",
    "              \"Target\":[\"C0\",\"C0\",\"C0\",\"C0\",\"C0\",\"C0\",\"C0\",\"C0\",\"C0\",\"C0\",\"C1\",\"C1\",\"C1\",\"C1\",\"C1\",\"C1\",\"C1\",\"C1\",\"C1\",\"C1\"]}\n",
    "pd_exr_3 = pd.DataFrame(data=exercise_3)\n",
    "\n",
    "pd_pos_class = pd_exr_3[pd_exr_3[\"Target\"] == \"C0\"]\n",
    "pd_neg_class = pd_exr_3[pd_exr_3[\"Target\"] == \"C1\"]\n",
    "count_poss = np.square(pd_pos_class[\"Target\"].count()/pd_exr_3[\"Target\"].count())\n",
    "count_negs = np.square(pd_neg_class[\"Target\"].count()/pd_exr_3[\"Target\"].count())\n",
    "gini = 1 - (count_poss + count_negs)\n",
    "print(gini)\n",
    "pd_exr_3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "def my_gini(panda, col):\n",
    "    grouping = panda.groupby(col)[col]\n",
    "    prob_array = grouping.count()/panda[col].count()\n",
    "    p = 0\n",
    "    names = []\n",
    "    for name, _ in grouping:\n",
    "        names.append(name)\n",
    "    for i in range(len(prob_array)):\n",
    "        p+=np.square(prob_array[names[i]])\n",
    "    gini = 1 - p\n",
    "    return gini\n",
    "print(my_gini(pd_exr_3, \"Cust ID\"))\n",
    "print(my_gini(pd_exr_3, \"Gender\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "*****\n",
    "\n",
    "Load the iris sample dataset from sklearn **loadiris()** into Python using a Pandas dataframe.  Induce a set of binary Decision Trees with a minimum of 2 instances in the leaves, no splits of subsets below 5, and an maximal tree depth from 1 to 5 (you can leave the majority parameter to 95%).  Which depth values result in the highest Recall? Why? Which value resulted in the lowest Precision? Why?  Which value results in the best F1 score?  Explain the difference between the micro/macro/weighted methods of score calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.057333           3.758000   \n",
       "std             0.828066          0.435866           1.765298   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)     species  \n",
       "count        150.000000  150.000000  \n",
       "mean           1.199333    1.000000  \n",
       "std            0.762238    0.819232  \n",
       "min            0.100000    0.000000  \n",
       "25%            0.300000    0.000000  \n",
       "50%            1.300000    1.000000  \n",
       "75%            1.800000    2.000000  \n",
       "max            2.500000    2.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "pd_iris = pd.DataFrame(data = np.c_[iris.data, iris.target], columns = iris.feature_names+['species'])\n",
    "\n",
    "pd_iris.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, target_train, target_test = model_selection.train_test_split(iris.data,\n",
    "                                                                    iris.target,\n",
    "                                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------Tree with depth: 1 -----------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       0.37      1.00      0.54         7\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "   micro avg       0.60      0.60      0.60        30\n",
      "   macro avg       0.46      0.67      0.51        30\n",
      "weighted avg       0.45      0.60      0.49        30\n",
      "\n",
      "----------------------------Confusion Matrix---------------------------\n",
      "\n",
      "[[11  0  0]\n",
      " [ 0  7  0]\n",
      " [ 0 12  0]]\n",
      "\n",
      "----------------------------Tree with depth: 2 -----------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00         7\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "----------------------------Confusion Matrix---------------------------\n",
      "\n",
      "[[11  0  0]\n",
      " [ 0  7  0]\n",
      " [ 0  0 12]]\n",
      "\n",
      "----------------------------Tree with depth: 3 -----------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00         7\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "----------------------------Confusion Matrix---------------------------\n",
      "\n",
      "[[11  0  0]\n",
      " [ 0  7  0]\n",
      " [ 0  0 12]]\n",
      "\n",
      "----------------------------Tree with depth: 4 -----------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00         7\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "----------------------------Confusion Matrix---------------------------\n",
      "\n",
      "[[11  0  0]\n",
      " [ 0  7  0]\n",
      " [ 0  0 12]]\n",
      "\n",
      "----------------------------Tree with depth: 5 -----------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00         7\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "----------------------------Confusion Matrix---------------------------\n",
      "\n",
      "[[11  0  0]\n",
      " [ 0  7  0]\n",
      " [ 0  0 12]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahmoud/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    predicted = DecisionTreeClassifier(max_depth = (i+1), min_samples_leaf = 2, min_samples_split = 5).fit(data_train, target_train).predict(data_test)\n",
    "    print(\"----------------------------Tree with depth: \" + str(i+1)+\" -----------------------\\n\")\n",
    "    print(metrics.classification_report(target_test,\n",
    "                                    predicted))\n",
    "    print(\"----------------------------Confusion Matrix---------------------------\\n\")\n",
    "    print(metrics.confusion_matrix(target_test,\n",
    "                               predicted))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "***\n",
    "Load the **Breast Cancer Wisconsin (Diagnostic)** sample dataset from the **UCI Machine Learning Repository** (The discrete version at: **breast-cancer-wisconsin.data**)  into Python using  a  Pandas  dataframe.   Induce  a  binary Decision Tree with a minimum of 2 instances in the leaves, no splits of subsets below 5, and a maximal tree depth of 2 (use the default Gini criterion). Calculate the  Entropy,  Gini,  and  Misclassification  Error  of  the  first  split  -  what  is  the Information  Gain?   What  is  the  feature  selected  for  the  first  split,  and  what value determines the decision boundary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clump Thickness                0\n",
       "Uniformity of Cell Size        0\n",
       "Uniformity of Cell Shape       0\n",
       "Marginal Adhesion              0\n",
       "Single Epithelial Cell Size    0\n",
       "Bare Nuclei                    0\n",
       "Bland Chromatin                0\n",
       "Normal Nucleoli                0\n",
       "Mitoses                        0\n",
       "Class:                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\", header=None)\n",
    "breast.columns=[\"Sample code number\",\"Clump Thickness\", \"Uniformity of Cell Size\", \"Uniformity of Cell Shape\", \n",
    "                \"Marginal Adhesion\", \"Single Epithelial Cell Size\",\"Bare Nuclei\", \"Bland Chromatin\", \n",
    "                \"Normal Nucleoli\", \"Mitoses\", \"Class:\"]\n",
    "breast_pd = breast.drop(columns=[\"Sample code number\"])\n",
    "nan_breast_pd = breast_pd.replace(to_replace=\"?\",value=0)\n",
    "nan_breast_pd.isna().sum() #All the nan values are in Bare Nuclei column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.417740</td>\n",
       "      <td>3.134478</td>\n",
       "      <td>3.207439</td>\n",
       "      <td>2.806867</td>\n",
       "      <td>3.216023</td>\n",
       "      <td>3.437768</td>\n",
       "      <td>2.866953</td>\n",
       "      <td>1.589413</td>\n",
       "      <td>2.689557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.815741</td>\n",
       "      <td>3.051459</td>\n",
       "      <td>2.971913</td>\n",
       "      <td>2.855379</td>\n",
       "      <td>2.214300</td>\n",
       "      <td>2.438364</td>\n",
       "      <td>3.053634</td>\n",
       "      <td>1.715078</td>\n",
       "      <td>0.951273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
       "count       699.000000               699.000000                699.000000   \n",
       "mean          4.417740                 3.134478                  3.207439   \n",
       "std           2.815741                 3.051459                  2.971913   \n",
       "min           1.000000                 1.000000                  1.000000   \n",
       "25%           2.000000                 1.000000                  1.000000   \n",
       "50%           4.000000                 1.000000                  1.000000   \n",
       "75%           6.000000                 5.000000                  5.000000   \n",
       "max          10.000000                10.000000                 10.000000   \n",
       "\n",
       "       Marginal Adhesion  Single Epithelial Cell Size  Bland Chromatin  \\\n",
       "count         699.000000                   699.000000       699.000000   \n",
       "mean            2.806867                     3.216023         3.437768   \n",
       "std             2.855379                     2.214300         2.438364   \n",
       "min             1.000000                     1.000000         1.000000   \n",
       "25%             1.000000                     2.000000         2.000000   \n",
       "50%             1.000000                     2.000000         3.000000   \n",
       "75%             4.000000                     4.000000         5.000000   \n",
       "max            10.000000                    10.000000        10.000000   \n",
       "\n",
       "       Normal Nucleoli     Mitoses      Class:  \n",
       "count       699.000000  699.000000  699.000000  \n",
       "mean          2.866953    1.589413    2.689557  \n",
       "std           3.053634    1.715078    0.951273  \n",
       "min           1.000000    1.000000    2.000000  \n",
       "25%           1.000000    1.000000    2.000000  \n",
       "50%           1.000000    1.000000    2.000000  \n",
       "75%           4.000000    1.000000    4.000000  \n",
       "max          10.000000   10.000000    4.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_breast_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Uniformity of Cell Size', 'Bland Chromatin', 'Mitoses', 'Mitoses',\n",
       "       'Uniformity of Cell Shape', 'Mitoses', 'Mitoses'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_tree = DecisionTreeClassifier(max_depth = 2, min_samples_leaf = 2, min_samples_split = 5)\n",
    "fitted_breast = breast_tree.fit(nan_breast_pd.drop(columns=[\"Class:\",\"Bare Nuclei\"]), nan_breast_pd[\"Class:\"])\n",
    "nan_breast_pd.columns[fitted_breast.tree_.feature] #Order of splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.88020446, 0.07898489, 0.        , 0.        ,\n",
       "       0.        , 0.04081065, 0.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_breast.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 10 columns):\n",
      "Clump Thickness                699 non-null int64\n",
      "Uniformity of Cell Size        699 non-null int64\n",
      "Uniformity of Cell Shape       699 non-null int64\n",
      "Marginal Adhesion              699 non-null int64\n",
      "Single Epithelial Cell Size    699 non-null int64\n",
      "Bare Nuclei                    699 non-null object\n",
      "Bland Chromatin                699 non-null int64\n",
      "Normal Nucleoli                699 non-null int64\n",
      "Mitoses                        699 non-null int64\n",
      "Class:                         699 non-null int64\n",
      "dtypes: int64(9), object(1)\n",
      "memory usage: 54.7+ KB\n"
     ]
    }
   ],
   "source": [
    "nan_breast_pd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 10 columns):\n",
      "Clump Thickness                699 non-null int64\n",
      "Uniformity of Cell Size        699 non-null int64\n",
      "Uniformity of Cell Shape       699 non-null int64\n",
      "Marginal Adhesion              699 non-null int64\n",
      "Single Epithelial Cell Size    699 non-null int64\n",
      "Bare Nuclei                    699 non-null float64\n",
      "Bland Chromatin                699 non-null int64\n",
      "Normal Nucleoli                699 non-null int64\n",
      "Mitoses                        699 non-null int64\n",
      "Class:                         699 non-null int64\n",
      "dtypes: float64(1), int64(9)\n",
      "memory usage: 54.7 KB\n"
     ]
    }
   ],
   "source": [
    "nan_breast_pd[\"Bare Nuclei\"] = nan_breast_pd[\"Bare Nuclei\"].astype(np.float64)\n",
    "nan_breast_pd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clump Thickness                0\n",
       "Uniformity of Cell Size        0\n",
       "Uniformity of Cell Shape       0\n",
       "Marginal Adhesion              0\n",
       "Single Epithelial Cell Size    0\n",
       "Bare Nuclei                    0\n",
       "Bland Chromatin                0\n",
       "Normal Nucleoli                0\n",
       "Mitoses                        0\n",
       "Class:                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_breast_pd = nan_breast_pd\n",
    "imp_breast_pd.columns = nan_breast_pd.columns\n",
    "imp_breast_pd.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Uniformity of Cell Size', 'Bare Nuclei', 'Mitoses', 'Mitoses',\n",
       "       'Uniformity of Cell Shape', 'Mitoses', 'Mitoses'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_fitted_breast = breast_tree.fit(imp_breast_pd.drop(columns=[\"Class:\"]), nan_breast_pd[\"Class:\"])\n",
    "imp_breast_pd.columns[new_fitted_breast.tree_.feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.87550059, 0.07856279, 0.        , 0.        ,\n",
       "       0.04593662, 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_fitted_breast.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.5,  5.5, -2. , -2. ,  2.5, -2. , -2. ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_fitted_breast.tree_.threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2575857338820302"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_right = new_fitted_breast.tree_.children_right[0] #4\n",
    "new_fitted_breast.tree_.impurity[index_right]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05437918724632007"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_left = new_fitted_breast.tree_.children_left[0] # 1\n",
    "new_fitted_breast.tree_.impurity[index_left]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5\n",
      "Uniformity of Cell Size\n"
     ]
    }
   ],
   "source": [
    "tresh = new_fitted_breast.tree_.threshold[0]\n",
    "print(tresh)\n",
    "f1 = imp_breast_pd.columns[new_fitted_breast.tree_.feature[0]]\n",
    "\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rightchild = imp_breast_pd[imp_breast_pd[f1] > tresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.766667</td>\n",
       "      <td>6.359259</td>\n",
       "      <td>6.214815</td>\n",
       "      <td>5.211111</td>\n",
       "      <td>5.074074</td>\n",
       "      <td>6.840741</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>5.514815</td>\n",
       "      <td>2.418519</td>\n",
       "      <td>3.696296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.576921</td>\n",
       "      <td>2.646560</td>\n",
       "      <td>2.708613</td>\n",
       "      <td>3.246369</td>\n",
       "      <td>2.468025</td>\n",
       "      <td>3.606145</td>\n",
       "      <td>2.442499</td>\n",
       "      <td>3.404262</td>\n",
       "      <td>2.462890</td>\n",
       "      <td>0.719087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
       "count       270.000000               270.000000                270.000000   \n",
       "mean          6.766667                 6.359259                  6.214815   \n",
       "std           2.576921                 2.646560                  2.708613   \n",
       "min           1.000000                 3.000000                  1.000000   \n",
       "25%           5.000000                 4.000000                  4.000000   \n",
       "50%           7.000000                 6.000000                  6.000000   \n",
       "75%           9.000000                 9.000000                  8.000000   \n",
       "max          10.000000                10.000000                 10.000000   \n",
       "\n",
       "       Marginal Adhesion  Single Epithelial Cell Size  Bare Nuclei  \\\n",
       "count         270.000000                   270.000000   270.000000   \n",
       "mean            5.211111                     5.074074     6.840741   \n",
       "std             3.246369                     2.468025     3.606145   \n",
       "min             1.000000                     2.000000     0.000000   \n",
       "25%             2.000000                     3.000000     3.000000   \n",
       "50%             5.000000                     5.000000     9.000000   \n",
       "75%             8.000000                     6.000000    10.000000   \n",
       "max            10.000000                    10.000000    10.000000   \n",
       "\n",
       "       Bland Chromatin  Normal Nucleoli     Mitoses      Class:  \n",
       "count       270.000000       270.000000  270.000000  270.000000  \n",
       "mean          5.600000         5.514815    2.418519    3.696296  \n",
       "std           2.442499         3.404262    2.462890    0.719087  \n",
       "min           1.000000         1.000000    1.000000    2.000000  \n",
       "25%           3.000000         3.000000    1.000000    4.000000  \n",
       "50%           6.000000         5.000000    1.000000    4.000000  \n",
       "75%           7.000000         9.000000    3.000000    4.000000  \n",
       "max          10.000000        10.000000   10.000000    4.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rightchild.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftchild = imp_breast_pd[imp_breast_pd[f1] <= tresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.939394</td>\n",
       "      <td>1.104895</td>\n",
       "      <td>1.314685</td>\n",
       "      <td>1.293706</td>\n",
       "      <td>2.046620</td>\n",
       "      <td>1.337995</td>\n",
       "      <td>2.076923</td>\n",
       "      <td>1.200466</td>\n",
       "      <td>1.067599</td>\n",
       "      <td>2.055944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.756446</td>\n",
       "      <td>0.306776</td>\n",
       "      <td>0.704653</td>\n",
       "      <td>0.855156</td>\n",
       "      <td>0.786967</td>\n",
       "      <td>1.311337</td>\n",
       "      <td>1.068300</td>\n",
       "      <td>0.846598</td>\n",
       "      <td>0.527380</td>\n",
       "      <td>0.330170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
       "count       429.000000               429.000000                429.000000   \n",
       "mean          2.939394                 1.104895                  1.314685   \n",
       "std           1.756446                 0.306776                  0.704653   \n",
       "min           1.000000                 1.000000                  1.000000   \n",
       "25%           1.000000                 1.000000                  1.000000   \n",
       "50%           3.000000                 1.000000                  1.000000   \n",
       "75%           4.000000                 1.000000                  1.000000   \n",
       "max          10.000000                 2.000000                  4.000000   \n",
       "\n",
       "       Marginal Adhesion  Single Epithelial Cell Size  Bare Nuclei  \\\n",
       "count         429.000000                   429.000000   429.000000   \n",
       "mean            1.293706                     2.046620     1.337995   \n",
       "std             0.855156                     0.786967     1.311337   \n",
       "min             1.000000                     1.000000     0.000000   \n",
       "25%             1.000000                     2.000000     1.000000   \n",
       "50%             1.000000                     2.000000     1.000000   \n",
       "75%             1.000000                     2.000000     1.000000   \n",
       "max            10.000000                    10.000000    10.000000   \n",
       "\n",
       "       Bland Chromatin  Normal Nucleoli     Mitoses      Class:  \n",
       "count       429.000000       429.000000  429.000000  429.000000  \n",
       "mean          2.076923         1.200466    1.067599    2.055944  \n",
       "std           1.068300         0.846598    0.527380    0.330170  \n",
       "min           1.000000         1.000000    1.000000    2.000000  \n",
       "25%           1.000000         1.000000    1.000000    2.000000  \n",
       "50%           2.000000         1.000000    1.000000    2.000000  \n",
       "75%           3.000000         1.000000    1.000000    2.000000  \n",
       "max           7.000000        10.000000    8.000000    4.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leftchild.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy for left child is 0.18411742692826688\n",
      "Gini for left child is 0.05437918724632018\n",
      "Classification error for left child is 0.027972027972028024\n"
     ]
    }
   ],
   "source": [
    "left_tot = leftchild[\"Class:\"].count()\n",
    "left_c1 = leftchild[leftchild[\"Class:\"] == 2].count()[\"Class:\"]\n",
    "left_c2 = leftchild[leftchild[\"Class:\"] == 4].count()[\"Class:\"]\n",
    "left_p = [left_c1/left_tot, left_c2/left_tot]\n",
    "ent = 0\n",
    "gini = 0\n",
    "for i in range(len(left_p)):\n",
    "    ent += -left_p[i]*np.log2(left_p[i])\n",
    "    gini += left_p[i]**2\n",
    "gini= 1 - gini\n",
    "\n",
    "print(\"Entropy for left child is\", ent)\n",
    "print(\"Gini for left child is\", gini)\n",
    "print(\"Classification error for left child is\", 1-max(left_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy for left child is 0.6144552279266028\n",
      "Gini for left child is 0.2575857338820302\n",
      "Classification error for left child is 0.1518518518518519\n"
     ]
    }
   ],
   "source": [
    "right_tot = rightchild[\"Class:\"].count()\n",
    "right_c1 = rightchild[rightchild[\"Class:\"] == 2].count()[\"Class:\"]\n",
    "right_c2 = rightchild[rightchild[\"Class:\"] == 4].count()[\"Class:\"]\n",
    "right_p = [right_c1/right_tot, right_c2/right_tot]\n",
    "ent1 = 0\n",
    "gini1 = 0\n",
    "for j in range(len(right_p)):\n",
    "    ent1 += -right_p[j]*np.log2(right_p[j])\n",
    "    gini1 += right_p[j]**2\n",
    "gini1= 1 - gini1\n",
    "\n",
    "print(\"Entropy for left child is\", ent1)\n",
    "print(\"Gini for left child is\", gini1)\n",
    "print(\"Classification error for left child is\", 1-max(right_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "Load the **Breast Cancer Wisconsin (Diagnostic)** sample dataset from the **UCI Machine  Learning  Repository**  (The continuous version  at: **wdbc.data**)  into Python using  a  Pandas  dataframe.   Induce  the  same  binary  Decision  Tree as above (now using the continuous data) but perform a PCA dimensionality reduction beforehand.  Using only the first principal component of the data for a model fit, what is the F1, Precision, and Recall of the PCA-based single factor model compared to the original (continuous) data?  Repeat using the first and second principal components.  Using the Confusion Matrix, what are the values for  FP  and  TP  as  well  as  FPR/TPR?  Is  using  continuous  data  in  this  case beneficial within the model?  How?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_breast_pd = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\", header=None)\n",
    "#cont_breast_pd.columns = [\"ID\", \"Diagnosis\",radius\",\"texture\", \"perimeter\", \"area\", \"smoothness\",\"compactness\",\n",
    " #                         \"concavity\",\"concave points\",\"symmetry\",\"fractal dimension\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      "0     569 non-null int64\n",
      "1     569 non-null object\n",
      "2     569 non-null float64\n",
      "3     569 non-null float64\n",
      "4     569 non-null float64\n",
      "5     569 non-null float64\n",
      "6     569 non-null float64\n",
      "7     569 non-null float64\n",
      "8     569 non-null float64\n",
      "9     569 non-null float64\n",
      "10    569 non-null float64\n",
      "11    569 non-null float64\n",
      "12    569 non-null float64\n",
      "13    569 non-null float64\n",
      "14    569 non-null float64\n",
      "15    569 non-null float64\n",
      "16    569 non-null float64\n",
      "17    569 non-null float64\n",
      "18    569 non-null float64\n",
      "19    569 non-null float64\n",
      "20    569 non-null float64\n",
      "21    569 non-null float64\n",
      "22    569 non-null float64\n",
      "23    569 non-null float64\n",
      "24    569 non-null float64\n",
      "25    569 non-null float64\n",
      "26    569 non-null float64\n",
      "27    569 non-null float64\n",
      "28    569 non-null float64\n",
      "29    569 non-null float64\n",
      "30    569 non-null float64\n",
      "31    569 non-null float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.3+ KB\n"
     ]
    }
   ],
   "source": [
    "cont_breast_pd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               2           3           4            5           6   \\\n",
       "count  569.000000  569.000000  569.000000   569.000000  569.000000   \n",
       "mean    14.127292   19.289649   91.969033   654.889104    0.096360   \n",
       "std      3.524049    4.301036   24.298981   351.914129    0.014064   \n",
       "min      6.981000    9.710000   43.790000   143.500000    0.052630   \n",
       "25%     11.700000   16.170000   75.170000   420.300000    0.086370   \n",
       "50%     13.370000   18.840000   86.240000   551.100000    0.095870   \n",
       "75%     15.780000   21.800000  104.100000   782.700000    0.105300   \n",
       "max     28.110000   39.280000  188.500000  2501.000000    0.163400   \n",
       "\n",
       "               7           8           9           10          11     ...      \\\n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000     ...       \n",
       "mean     0.104341    0.088799    0.048919    0.181162    0.062798     ...       \n",
       "std      0.052813    0.079720    0.038803    0.027414    0.007060     ...       \n",
       "min      0.019380    0.000000    0.000000    0.106000    0.049960     ...       \n",
       "25%      0.064920    0.029560    0.020310    0.161900    0.057700     ...       \n",
       "50%      0.092630    0.061540    0.033500    0.179200    0.061540     ...       \n",
       "75%      0.130400    0.130700    0.074000    0.195700    0.066120     ...       \n",
       "max      0.345400    0.426800    0.201200    0.304000    0.097440     ...       \n",
       "\n",
       "               22          23          24           25          26  \\\n",
       "count  569.000000  569.000000  569.000000   569.000000  569.000000   \n",
       "mean    16.269190   25.677223  107.261213   880.583128    0.132369   \n",
       "std      4.833242    6.146258   33.602542   569.356993    0.022832   \n",
       "min      7.930000   12.020000   50.410000   185.200000    0.071170   \n",
       "25%     13.010000   21.080000   84.110000   515.300000    0.116600   \n",
       "50%     14.970000   25.410000   97.660000   686.500000    0.131300   \n",
       "75%     18.790000   29.720000  125.400000  1084.000000    0.146000   \n",
       "max     36.040000   49.540000  251.200000  4254.000000    0.222600   \n",
       "\n",
       "               27          28          29          30          31  \n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000  \n",
       "mean     0.254265    0.272188    0.114606    0.290076    0.083946  \n",
       "std      0.157336    0.208624    0.065732    0.061867    0.018061  \n",
       "min      0.027290    0.000000    0.000000    0.156500    0.055040  \n",
       "25%      0.147200    0.114500    0.064930    0.250400    0.071460  \n",
       "50%      0.211900    0.226700    0.099930    0.282200    0.080040  \n",
       "75%      0.339100    0.382900    0.161400    0.317900    0.092080  \n",
       "max      1.058000    1.252000    0.291000    0.663800    0.207500  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cont_breast_pd = cont_breast_pd.drop(columns=[0,1])\n",
    "data_cont_breast_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.2045 0.982045\n",
      "1.6176 0.016176\n",
      "0.1558 0.001558\n",
      "0.0121 0.000121\n",
      "0.0088 8.8e-05\n",
      "0.0007 7e-06\n",
      "0.00039999999999999996 4e-06\n",
      "9.999999999999999e-05 1e-06\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "pca_breast = PCA()\n",
    "fitted_pca = pca_breast.fit(data_cont_breast_pd)\n",
    "pca_breast_percent_var = np.around(pca_breast.explained_variance_ratio_, 6)\n",
    "for i in range(len(pca_breast_percent_var)):\n",
    "    print(pca_breast_percent_var[i]*100, pca_breast_percent_var[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98204467])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_pca_breast = PCA(n_components =1)\n",
    "first_pca_comp = first_pca_breast.fit_transform(data_cont_breast_pd)\n",
    "first_pca_breast.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.8361815189016306e-14"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_pca_comp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.95      0.96      0.95        73\n",
      "           M       0.93      0.90      0.91        41\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       114\n",
      "   macro avg       0.94      0.93      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "[[70  3]\n",
      " [ 4 37]]\n"
     ]
    }
   ],
   "source": [
    "breast_x, breast_x_test, breast_y, breast_y_test = model_selection.train_test_split(first_pca_comp,\n",
    "                                                                    cont_breast_pd[1],\n",
    "                                                                    test_size=0.2)\n",
    "dt_breast = DecisionTreeClassifier(max_depth = 2, min_samples_leaf = 2,min_samples_split = 5).fit(breast_x, breast_y)\n",
    "\n",
    "\n",
    "#print(\"----------------------------Tree with depth classification-----------------------\\n\")\n",
    "print(metrics.classification_report(breast_y_test, dt_breast.predict(breast_x_test)))\n",
    "#print(\"----------------------------Confusion Matrix---------------------------\\n\")\n",
    "print(metrics.confusion_matrix(breast_y_test,dt_breast.predict(breast_x_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.90      0.94      0.92        67\n",
      "           M       0.91      0.85      0.88        47\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       114\n",
      "   macro avg       0.90      0.90      0.90       114\n",
      "weighted avg       0.90      0.90      0.90       114\n",
      "\n",
      "[[63  4]\n",
      " [ 7 40]]\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data, train_target, test_target = model_selection.train_test_split(data_cont_breast_pd,\n",
    "                                                                    cont_breast_pd[1],\n",
    "                                                                    test_size=0.2)\n",
    "dt_cont_breast = DecisionTreeClassifier(max_depth = 2, min_samples_leaf = 2,min_samples_split = 5).fit(train_data, train_target)\n",
    "\n",
    "\n",
    "#print(\"----------------------------Tree with depth classification-----------------------\\n\")\n",
    "print(metrics.classification_report(test_target, dt_cont_breast.predict(test_data)))\n",
    "#print(\"----------------------------Confusion Matrix---------------------------\\n\")\n",
    "print(metrics.confusion_matrix(test_target,dt_cont_breast.predict(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98204467, 0.01617649])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_pca_breast = PCA(n_components =2)\n",
    "two_pca_comp = two_pca_breast.fit_transform(data_cont_breast_pd)\n",
    "two_pca_breast.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1160.1425737 , -293.91754364],\n",
       "       [1269.12244319,   15.63018184],\n",
       "       [ 995.79388896,   39.15674324],\n",
       "       ...,\n",
       "       [ 314.50175618,   47.55352518],\n",
       "       [1124.85811531,   34.12922497],\n",
       "       [-771.52762188,  -88.64310636]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_pca_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.87      0.99      0.92        74\n",
      "           M       0.97      0.72      0.83        40\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       114\n",
      "   macro avg       0.92      0.86      0.88       114\n",
      "weighted avg       0.90      0.89      0.89       114\n",
      "\n",
      "[[73  1]\n",
      " [11 29]]\n"
     ]
    }
   ],
   "source": [
    "train2_data, test2_data, train2_target, test2_target = model_selection.train_test_split(two_pca_comp,\n",
    "                                                                    cont_breast_pd[1],\n",
    "                                                                    test_size=0.2)\n",
    "dt_cont_breast = DecisionTreeClassifier(max_depth = 2, min_samples_leaf = 2,\n",
    "                                        min_samples_split = 5).fit(train2_data, train2_target)\n",
    "\n",
    "\n",
    "#print(\"----------------------------Tree with depth classification-----------------------\\n\")\n",
    "print(metrics.classification_report(test2_target, dt_cont_breast.predict(test2_data)))\n",
    "#print(\"----------------------------Confusion Matrix---------------------------\\n\")\n",
    "print(metrics.confusion_matrix(test2_target,dt_cont_breast.predict(test2_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "Simulate a binary classification dataset with a single feature using a mixture of normal distributions with NumPy(Hint:  Generate two data frames with the random  number  and  a  class  label,  and  combine  them  together).   The  normal distribution  parameters  **np.random.normal**  should  be  (5,2)  and  (-5,2)  for the pair of samples.  Induce a binary Decision Tree of maximum depth 2, and obtain the threshold value for the feature in the first split.  How does this value compare to the empirical distribution of the feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.002313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.293827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-10.353750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.923400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.061132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.857598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.926335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                f1\n",
       "count  1000.000000\n",
       "mean     -0.002313\n",
       "std       5.293827\n",
       "min     -10.353750\n",
       "25%      -4.923400\n",
       "50%      -0.061132\n",
       "75%       4.857598\n",
       "max       9.926335"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(267) #267\n",
    "rand_data_1 = np.random.normal(5,2,500 )\n",
    "rand_data_2 = np.random.normal(-5, 2, 1000-500)\n",
    "class_1 = np.repeat(\"c1\", 500)\n",
    "class_2 = np.repeat(\"c2\", 1000-500)\n",
    "pd_1 = pd.DataFrame(dict(zip(['f1','Class'],[rand_data_1,class_1])))\n",
    "pd_2 = pd.DataFrame(dict(zip(['f1','Class'],[rand_data_2,class_2])))\n",
    "rand_data_frame = pd.concat([pd_1,pd_2])\n",
    "rand_data_frame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.024599768152704"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_data_frame[\"f1\"].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.48002306, -0.90108308, -2.        , -2.        ,  0.72923988,\n",
       "       -2.        , -2.        ])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_rand = DecisionTreeClassifier(max_depth = 2).fit(rand_data_frame.drop(columns=[\"Class\"]), rand_data_frame[\"Class\"])\n",
    "dt_rand.tree_.threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['f1', 'f1', 'f1', 'f1', 'f1', 'f1', 'f1'], dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_data_frame.columns[dt_rand.tree_.feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 0 to 499\n",
      "Data columns (total 2 columns):\n",
      "f1       1000 non-null float64\n",
      "Class    1000 non-null object\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 23.4+ KB\n"
     ]
    }
   ],
   "source": [
    "rand_data_frame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1      -0.846103\n",
       "Class          c1\n",
       "dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_data_frame[rand_data_frame[\"Class\"] == \"c1\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1       0.728319\n",
       "Class          c2\n",
       "dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_data_frame[rand_data_frame[\"Class\"] == \"c2\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
